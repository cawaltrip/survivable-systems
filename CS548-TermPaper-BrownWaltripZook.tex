\documentclass[twoside, conference]{IEEEtran}%
% % % % % % % % % % % % % % %
% Packages Below            %
% % % % % % % % % % % % % % %
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage[usenames,dvipsnames]{color}
\usepackage{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{comment}
% % % % % % % % % % % % % % %
% Metadata                  %
% % % % % % % % % % % % % % %
\hypersetup{
	pdftitle={Emergent Data Fusion and Consensus Methods for Autonomous Vehicles and Wireless Sensor Networks},
	pdfauthor={Matt Brown; Chris Waltrip; Jared Zook},
	pdfsubject={University of Idaho; CS-548: Graduate Paper},
	pdfcreator={Chris Waltrip},
	pdfproducer={Chris Waltrip},
	linktoc=all, 			% Link the section number, text and page number in Contents
	colorlinks=false,       % Removes color frame and colors text instead
	linkcolor=ForestGreen,  % Default is red, may want to use black
	citecolor=Bittersweet,  % Default is green
	filecolor=Cyan,         % Default is cyan
	urlcolor=Magenta,       % Default is magenta
}%
% % % % % % % % % % % % % % %
% New square root style     %
% % % % % % % % % % % % % % %
\let\oldsqrt\sqrt
% \sqrt defined in terms of the original sqrt command
\def\sqrt{\mathpalette\DHLhksqrt}
\def\DHLhksqrt#1#2{%
	\setbox0=\hbox{$#1\oldsqrt{#2\,}$}\dimen0=\ht0
	\advance\dimen0-0.2\ht0
	\setbox2=\hbox{\vrule height\ht0 depth -\dimen0}%
	{\box0\lower0.4pt\box2}}%
% % % % % % % % % % % % % % %
% Title/Author Information  %
% % % % % % % % % % % % % % %
\title{Emergent Data Fusion and Consensus Methods for Autonomous Vehicles and Wireless Sensor Networks}
\author{
	\IEEEauthorblockN{Matt Brown}
	\IEEEauthorblockA{Department of Computer Science\\University of Idaho\\Moscow, Idaho 83843\\Email: \href{mailto:matt2714@vandals.uidaho.edu}{\nolinkurl{matt2714@vandals.uidaho.edu}}}
	\and
	\IEEEauthorblockN{Chris Waltrip}
	\IEEEauthorblockA{Department of Computer Science\\University of Idaho\\Moscow, Idaho 83843\\Email: \href{mailto:walt2178@vandals.uidaho.edu}{\nolinkurl{walt2178@vandals.uidaho.edu}}}
	\and
	\IEEEauthorblockN{Jared Zook}
	\IEEEauthorblockA{Department of Computer Science\\University of Idaho\\Moscow, Idaho 83843\\Email: \href{mailto:jzook@vandals.uidaho.edu}{\nolinkurl{jzook@vandals.uidaho.edu}}}
}%
\begin{document}
	\maketitle
	
	\begin{abstract}% Summarize the outline of the problems and findings
		This paper is a survey of recent research that addresses the problem of sensor failure in autonomous vehicles. Modern mathematical and fault models are presented, and their strengths and weaknesses are assessed. In particular, we consider the different faults that should be assumed, as well as any real-time constraints that are imposed in the environment.  Where possible, the explored fault models are compared to existing fault model taxonomies such as those found in \cite{Azadmanesh2000}.  Traditional fault models lacked the ability to systematically be applied to unmanned vehicles.  Instead, dynamic, hybrid fault models resilient to failures of links and nodes and node replacement were necessary.  These dynamic, hybrid fault models and agreement algorithms have practical applications that can be seen beyond just autonomous vehicles.  A game-theoretic framework pitting Byzantine generals against each other with a resiliency payoff helps explore the quality of dynamic fault models in wireless networks.
	\end{abstract}
	
	%% abstract needs more info about indiv research solutions

\section{Introduction and Background}\label{sec:introduction}
Autonomous vehicles rely on multi-sensor data fusion to gain perception of their surroundings.  Data fusion is an algorithmic process that merges information from multiple sensors to determine how the vehicle will operate in its environmental context (e.g. to determine its coordinates or to move to another location) \cite{Bader2014}.  Traditionally, fault models use these data fusion algorithms to detect and tolerate various hardware failures; the data fusion algorithms however may be the cause of faults - these software faults need to be protected as well \cite{Bader2014}.  As such, we find that traditional fault models should not blindly be applied in this domain.  An additional issue inherent to unmanned vehicles is that they receive input from local sensors and also from external sources. That data needs to match up accordingly, even in the presence of faults.  Wireless network fault models can be used to account for this issue \cite{Moniz2013}.

The agreement algorithms themselves are also required to be more robust due to the increased amount of sensors in autonomous vehicles versus manned vehicles \cite{Ren2001}.  We explore different consensus-finding methods under various conditions, including sensor failure (\cite{Ren2001}), centralized and decentralized sensor networks (\cite{Clouqueur2004,Biely2007}) and under communication link failure (\cite{Biely2011,Milosevic2014}).

\subsection{Outline}
This paper is organized into two primary parts.  First, various fault models for autonomous vehicles and wireless networks are explored.  Then, it transitions into the exploration and discussion of different types of agreement algorithms that could possibly be incorporated into the previously discussed fault models in domains beyond just autonomous vehicles.

In \cref{sec:ftmodel-autonomous} an architecture of a fault model for autonomous vehicles is explored.  \Cref{sec:wireless-faultmodels} focuses on fault models for wireless networks and specifically focuses on an asynchronous algorithm called ``Turquois'' for reaching consensus in the presence of Byzantine faults.  From there, \Cref{sec:toleratingfaults} looks at how to reach consensus while being able to tolerate corrupted communication when liveness and message safety are necessary.  Then in \cref{sec:sensornet-agreement} agreement in (primarily non-distributed) sensor networks is examined with emphasis both in value fusion and decision fusion algorithms.  \Cref{sec:adhoc-agreement} then discusses ad hoc agreement with respect to manned and unmanned vehicles.  Finally, \cref{sec:conclusions} contains conclusions and a summary of the different analyses made in this paper and discusses possible future work.

\section{A Fault Tolerant Model for Autonomous Vehicles}\label{sec:ftmodel-autonomous} %jz
Bader et al. developed an architecture that tolerates both hardware faults (e.g. in sensors) and software faults (e.g. in the data fusion algorithms themselves) and applied it to a vehicle localization application for mobile robots by using a Kalman filter, an error detection algorithm. This architecture assumes that a single value fault is active at a given time and relies on duplication and comparison for error detection \cite{Bader2014}.

Error detection is a vital aspect of fault tolerance. This task is often carried out by duplicating data from functionally identical components and comparing the results to see if they deviated from the expected results. Many fault-detection techniques rely on the data fusion algorithms themselves to detect and tolerate hardware errors. If no hardware errors are detected, the systems assume that proper agreement has been made. Bader argues that these methods fall short by considering only half of the picture; what if the faults stem from the data fusion process itself? The software side of the system, then, must be taken into consideration. Data fusion algorithms are difficult to design and validate. Therefore, fault detection and correction need to extend to the data fusion mechanisms themselves, which is the motivation for Bader's architecture \cite{Bader2014}.

Bader's architecture breaks down the error detection into multiple components: the sensor component, the data fusion component, and the fault-tolerant component. The sensor component and the data fusion component are broken up into two branches. Each branch contains, on the sensor side, two sensor blocks that require agreement, and, on the software side, a data fusion block. Output from the branches is sent to the fault-tolerant component, which includes an error detection module and an error identification and recovery model. The error detection module takes as input all the combined data processed in the branches and, in this implementation, applies a Kalman filter data fusion algorithm to detect errors. This algorithm estimates the expected state of the system, and iteratively corrects itself by comparing its prediction to the output received from the sensors. If an error is detected, the error information and the sensor data is coalesced in the error identification and recovery module which applies the appropriate correction estimated for the error \cite{Bader2014}.

One potential weakness of this system is that, in its current design, the restraints of the system allow it to react only to a single value fault at a time: either a hardware fault or a software fault. Though the implementation of the architecture was able to handle either fault, the limitation does not scale well. This is a concern considering that larger, survivable systems need to tolerate multiple faults across hardware and software. Bader addresses this shortcoming and suggests that an additional data fusion block, and the addition of a voting method, could better identify erroneous data fusion \cite{Bader2014}.

Another concern highlighted by the implementation of the architecture was that the detection delay for software faults was an order of magnitude higher than for the hardware faults: GPS and steering angle faults were detected in a matter of seconds whereas the software fault took more than a minute. Since autonomous vehicles operate in real-time, this delay could lead to system failure (e.g. if an AV were on railroad tracks with a train coming and was unable to recover from its software disagreement in time). This is not necessarily a flaw with Bader's system, but a way to highlight the importance for considering software faults in models and developing faster means to tolerate them \cite{Bader2014}.

\section{Wireless Network Fault Models}\label{sec:wireless-faultmodels}
Moniz, et al. developed ``Turquois'', an asynchronous protocol specifically designed to reach Byzantine consensus in wireless ad hoc networks. Turquois was developed because the authors found that traditional fault models did not match up well with the pervasive communication failures common to wireless ad hoc networks (e.g. ad hoc networks created and utilized by semi-autonomous vehicles in transit). Traditional models, such as the Lamport model, assumed general reliability among the \textit{links} of the different nodes in a system. That applies well enough to standard wired networks, however, the nature of wireless communication and the dynamic properties of mobile ad hoc networks give rise to unreliable connections due to, for example, interference, malicious jamming, and node mobility. Thus, it is necessary to develop expanded models that are better fit to the contingencies found in newer applications. As such, Turquois assumes an ad hoc, dynamic fault model \cite{Moniz2013}.

Turquois finds agreement in the presence of two faults: dynamic transmission omission faults (ones in which a message sent by $P_i$ is not received by $P_j$) and Byzantine faults (asymmetric faults such as collisions or false values sent). Its aim is to operate \textit{even with} the assumption that some messages are guaranteed to be permanently corrupted or lost on a transitory basis. Turquois uses a  round-based algorithm, with messages being transmitted each round, and the presence of faults is accounted for in the assumption. Accordingly, Turquois is able to tolerate dynamic message omissions and Byzantine faults and is safe despite the failure of $f < \frac{n}{3}$ nodes. Agreement is reached under this protocol when the conditions of Validity (each node with a correct value decides on that value), Agreement (all correct nodes decide the same), and Termination (voting terminates after a specified number of nodes have voted) are met \cite{Moniz2013}.

Wireless ad hoc networks are inherently resource-constrained, especially when compared with static systems. As such, computational expense is something implementers need to pay special attention to. To address this with the Turquois protocol, the authors eschewed the use of RSA-based public-key cryptography, which is computationally expensive. Instead, they used hash-based message authentication and claimed to achieve one entire order of magnitude of performance improvement when scaling their simulation to have a high number of nodes compared it to a public-key solution. There was no mention about whether or not eliminating RSA compromised security in any way \cite{Moniz2013}.

Ma and Krings \cite{Ma2008} explore some short-comings of traditional hybrid fault models and introduce a dynamic hybrid fault model. While traditional models set the basis for managing redundancy in fault-tolerant systems, they fall short when applied to dynamic systems such as Wireless Sensor Networks (WSN), where nodes may fail at different times. WSNs, then, require analysis of real-time processing mechanics, and consideration of other contingencies unique to the constraints of their environment. Traditional hybrid fault models, such as those proposed by Azadmanesh \cite{Azadmanesh2000}, do not account for timing of faulty behavior for example; they neglect to consider the situation that a fault seen at $t_0$ may transform into some other type of fault at $t_1$. To address this gap and to assume a fault model for WSNs, Ma and Krings assume a dynamic fault model that includes a time-dependent failure rate and time-dependent failure modes. The fault classifications from the traditional models are then seen as \textit{qualitative} parameters which, though they no longer serve as the foundation of the model, they are used as strategies in Evolutionary Game Theory (EGT) games \cite{Ma2008}.

Since the underpinnings of traditional reliability analysis are declared qualitative, an alternative fault model must be assumed. Ma and Krings suggest the addition of \textit{survivability analysis} to the traditional process which allows for consideration of time and covariant-dependent failures. To do this, survivor functions are included with agreement algorithms. Then, EGT games are used to simulate the reliability aspect of the model. In the EGT game, the qualitative categories from the traditional fault models serve as the constraints to the model and the Byzantine generals serve as the players of the game. When conducting EGT games, the hope is to arrive at an Evolutionary Stable Strategy (ESS) which leads a payoff: reliability \cite{Ma2008}.

\section{Obtaining Synchronous Consensus in the Presence of Corrupted Communication}\label{sec:toleratingfaults}
Biely discusses dynamic and transient faults; that is, faults that might affect any or all of the processes and faults that don't always exist \cite{Biely2007}.  Such a transmission fault occurs, for example, in a communication between process $p$ and process $q$, where what should be sent is message $m$; however, process $q$ instead receives message $m'$ \cite{Biely2007}.  There are three reasons that process $q$ may receive this message:
\begin{enumerate}
	\item $p$ actually sent $m'$ instead of $m$ and $q$ correctly receives $m'$;
	\item $p$ sends $m$ correctly, but $q$ improperly receives $m'$;
	\item $p$ sends $m$ correctly, but the communication channel between the two processes is faulty and corrupts the data into $m'$ and $q$ correctly receives the corrupted message \cite{Biely2007}.
\end{enumerate}
Biely introduces two algorithms, the HO (or Heard-Of) algorithm and SHO (Safe Heard-Of).  HO can be used when strong message safety has been assured beforehand but liveness conditions are weaker; SHO works on the other side of the spectrum where safety has not been guaranteed, but the liveliness of the data is necessary \cite{Biely2007}.  Simply put, the HO algorithm is designed to tolerate omissions of communication and the SHO algorithm is designed to tolerate corrupted communications \cite{Biely2007}.
Consensus can be achieved using the HO model as long as the following three conditions can be met.
\begin{enumerate}
	\item Integrity: If all processes share the same initial value then there is no other possible value to be decided on;
	\item Agreement: No two nodes may make a decision in a different way;
	\item Termination: All processes must eventually reach a decision \cite{Biely2007}.
\end{enumerate}
Consensus can be obtained for both HO and SHO machines provided that their restrictions placed on safety and liveness have been met.  The usefulness of these algorithms, it seems, is likely in situations where other methods of converting value faults to benign faults is not possible (for example, where using signed messages is computationally infeasible) \cite{Biely2007}.  The Byzantine Generals problem can be modeled as a predicate that can be used by the algorithms of this paper \cite{Biely2007}.  Further, there is a dynamic fault model that they also model as a predicate that is usable by their algorithms \cite{Biely2007}.

The idea of  ``eventual consistency'' is used in order to overcome the limitation of current solutions regarding consensus.  Specifically, the limitation that revolves around synchronous systems or systems with termination conditions that exclude situations where all messages can be corrupted \cite{Milosevic2014}.  For example, three algorithms for both benign and Byzantine transmission faults, including permanent ones using consensus \cite{Milosevic2014}.  Eventual consistency is the idea that there is at least one round of agreement where all nodes receive the same values \cite{Milosevic2014}.  The transmission fault model used is based on the HO and SHO sets (from \cite{Biely2007}) \cite{Milosevic2014}.  The three algorithms used are the 
\begin{enumerate}
	\item BOTR algorithm,
	\item BLV algorithm, and
	\item BLK algorithm \cite{Milosevic2014}.
\end{enumerate}
The three algorithms are used to show that the approach that is given is general in nature.  Each algorithm has a communication predicate that much be reached in order for termination to happen.  For $n$, the number of nodes, $f$, the number of Byzantine faulty nodes, and $\alpha$, the number of corrupted messages, the BOTR algorithm achieves resiliency at $n > 4\alpha + 3f$ and the BLV and BLK algorithms both at $n > 2\alpha + 2f$\cite{Milosevic2014}.  The paper argues that permanent value faults are indistinguishable from Byzantine faults and that due to this, the algorithms can also be used in partially synchronous models \cite{Milosevic2014}.  

The authors state that the algorithms (and their approach) can handle static or permanent faults, dynamic and transient faults, process faults and link faults \cite{Milosevic2014}.  Because of their transmission fault model being a modified version of the HO model (from \cite{Biely2007}), which the authors of this paper state can handle benign faults as well \cite{Milosevic2014}. It appears that their fault model is designed to handle both malicious and benign faults.  Further, the authors state that eventual consistency is based on eventual synchrony \cite{Milosevic2014} and that their algorithms are partially synchronous \cite{Milosevic2014}.  This fault model seems to be similar to the ``Five-Mode Omissive/Transmissive Hybrid Fault Model'' (OTH-5) from \cite{Azadmanesh2000} in that it handles all of the different types of symmetric/asymmetric faults as well as the benign faults.  Determining the computation and communication complexity of this is tough.  For example, the BOTR algorithm is based on a sequence of phases and each phase has two rounds \cite{Milosevic2014}.  However the number of phases is not defined; instead the condition of consistency needs to be met \cite{Milosevic2014}.

A hybrid fault model for synchronous, distributed agreement (consensus) algorithms where communication links between nodes can fail is discussed by \cite{Biely2011}.  It uses a round-based computing model where each process is modeled as a deterministic state machine.  Each process executes computing steps in perfect lock-step synchrony and can send and receive messages from a possibly infinite alphabet \cite{Biely2011}.  The failure model used consists of a matrix $\mathcal{R}^k$ of the messages received for round $k$, $\mathcal{M}^k$ the messages that should be sent by each process in round $k$ and $\mathcal{S}^k$, the messages actually sent by each process in round $k$ \cite{Biely2011}.  Using this failure model the following types of behaviors can be distinguished:
\begin{enumerate}
	\item Correct: A process always completes the algorithm correctly and sends the correct value at every round;
	\item Omission: A process fails to send its value to at least one of its receivers at least one time;
	\item Manifest: A process that is either omissive or sends a value to all receivers that can be detected at least one time;
	\item Symmetric: A process that sends the same bad value to all of its receivers;
	\item Arbitrary: A process that has no restrictions on sent messages \cite{Biely2011}.
\end{enumerate}
The paper continues by introducing a hybrid failure model that works for synchronous distributed algorithms \cite{Biely2011} and showed how a number of different consensus and Byzantine algorithms could be modified such that they can be used in the defined model.  Comparisons between algorithms that are exponential in terms of message complexity (such as the hybrid oral message (OMH) algorithm) against some of the polynomial algorithms (such as the Phase Queen and Phase King algorithms) in terms of their resilience and round complexity show that the polynomial algorithms both require more processes and require a minimum of twice the number of rounds to come to consensus \cite{Biely2011}.  Results also show that the reliable communication assumption that is traditionally used in the analysis of these algorithms is unnecessary \cite{Biely2011}.

This fault model assumes the possibility of both asymmetric and symmetric faults; in addition, faults can be detectable, omissive, transmissive or even arbitrary.  When comparing this fault model to different fault model taxonomies, such as the models discussed in \cite{Azadmanesh2000}, this model is similar to a five-mode (omissive/transmissive) hybrid fault model.



\section{Sensor Network Agreement}\label{sec:sensornet-agreement}
It is common for there to be sensor networks inside of an unmanned vehicle. These sensors need a method for agreeing on values. There are many different faults that can present in such a sensor network due to harsh environments that the vehicle is operating in. These faults range from crash, benign, to Byzantine faults. Clouqueurm, Saluja and Ramanathan describe the precision and accuracy of both value Fusion and Decision fusion algorithms in \cite{Clouqueur2004}. 

Sensor networks can be deployed in two different fashions, centralized and decentralized. In a centralized sensor network all nodes report their findings to a central processing unit, this is known as value fusion. In a decentralized sensor network all nodes agree on a value using an agreement algorithm and then report their findings, defined as decision fusion. In the sensor network described in the paper all sensors report their values using analog signals. This reduces the communication overhead that is normally required by digital signals. Because of the nature of the signal, noise can be introduced into the system creating the necessity for agreement. For value fusions the algorithm is described as such:
\begin{enumerate}
	\item obtain energy level from every node;
	\item drop largest \textit{n} and smallest \textit{n} values;
	\item compute average of remaining values;
	\item compare the average to the threshold for final decision \cite{Clouqueur2004}.
\end{enumerate}
In \cite{Clouqueur2004} the algorithm for decision fusion is as such:
\begin{enumerate}
	\item obtain local decision from every node;
	\item drop largest \textit{n} and smallest \textit{n} decisions;
	\item compute the average of remaining local decisions;
	\item compare the average to threshold for final decision \cite{Clouqueur2004}.
\end{enumerate}
If all nodes report the same value for step one of each algorithm, then step two can be skipped to save time \cite{Clouqueur2004}.

These algorithms are evaluated in terms of accuracy and precision. Accuracy is described as the distance between the agreed value and the real world condition. Precision is described as the distance between all values agreed upon. So far these algorithms show high precision. To compare the two algorithms presented above, decision fusion has a much smaller communication overhead cost due to the reduced information being distributed due to pre-agreement amongst local sensor nodes.

%There are other aspects to agreement algorithms that need to be evaluated.

For value fusion, the first of these is known as the probability density function (PDF). The PDF is described in the paper as the amount of noise energy that is assumed in the network. The equation for the PDF of an agreement is defined as:
\begin{equation}
f_x(x)=\frac{1}{\sqrt{2\pi x}}\exp[-\frac{x}{2}]I_{(0,\infty)}(x)%
\end{equation}
\cite{Clouqueur2004}. The next aspect is known as the false alarm probability. This is described as the probability that the agreed upon value is higher than the threshold in the absence of a target. The equation for the false alarm probability is given as:
\begin{equation}
P_{fa}=P[\frac{1}{N}\sum_{i=1}^{N}N_i>n_v]%
\end{equation}
where $N$ is the number of values measured by the sensors and $n$ is the threshold \cite{Clouqueur2004}.
The final aspect used to determine the efficiency of the sensor net is the detection probability. The detection probability is defined as the probability that a sensor network will detect an entity or a change in environment when there truly is one. This is given as:
\begin{equation}
P_d(u)=1-F_{x^2_N}(N_{n_{v}}-\sum_{i=1}^{N}E_i(u))%
\end{equation}
where $u$ is defined as the relative position of a target \cite{Clouqueur2004}.

Decision fusion also has these probabilities however they are defined in a slightly different manner.
The PDF function, however, is the same as with value fusion. The false alarm probability and detection probability are defined as:
\begin{equation}
P_{fa}=\sum_{i=\alpha N}^{N}\binom{N}{i}F_x(\eta d)^{N-i}(1-F_x(\eta d))^i%
\end{equation} 
\begin{equation}
\begin{split}
P_d=\sum_{i=[\alpha N]}^{N}\sum_{h \in C_{i,N}}^{}[\prod_{j=1}^{i}(1-F_x(\eta d - E_{h(j)}(u)))\\\prod_{j=i+1}^{N} F_X(\eta_d-E_{h(j)}(u)]%
\end{split}
\end{equation}
respectively \cite{Clouqueur2004}. By analyzing these functions we can see that decision fusion is much more likely to detect a present object than value fusion. It is also worthy noting that the probability of a false alarm occurring when implementing decision fusion increases as well.

Faults and errors can be prevented in this scheme by removing the max and min values during each voting session. If a target is truly there then more than one sensor will see it making the value persist beyond the removed extremes.

\section{Ad Hoc Agreement}\label{sec:adhoc-agreement}
Unmanned vehicles have a much higher sensor count than manned vehicles. These sensors include proximity sensors, RADAR, LIDAR, and GPS. These sensors are deployed in networks that have to agree on input values so they can be process accurately. In order for these sensors to agree they need to be implemented redundantly. An agreement method adapted from Yansong Ren and associates can be applied to this situation \cite{Ren2001}. In this algorithm they describe a set of redundant nodes that communicate through locally before broadcasting the results. If we adapt this algorithm to a real-world sensor net, then a physically local group of sensors can be treated as a redundant group. This redundant group can agree on their readings via a majority algorithm or median agreement algorithm to remove the readings of nodes in the group that read nothing. Once the sensor nodes have an agreed value they can pass the information to the main computer or processing module via multicast so all redundant nodes and the main processing module receive the same value. Through this method the transmitting node is held accountable to the value agreed \cite{Ren2001}.

Ren's paper also describes a method for removing or replacing faulting nodes. This method includes a manager that checks the value sent from the transmitting node to check for faults. This method describes ``replacing'' faulting nodes with new nodes. In an unmanned vehicle this method is not very practical. This idea can be adapted, however, to a module that can detect faulting modules that ``pushes'' new copies of firmware to a faulting sensor in an attempt to repair it. This method fails if a sensor is physically damaged.\cite{Ren2001}

Another aspect of redundancy that should be addressed is faulting nodes due to a failure in communication. If the communication system in an unmanned vehicle is designed to be self-repairing through redundancy, it can take some time for the module to notice the failing path. In this case, there needs to be a method for reintegrating sensors once communication is reestablished. A paper written by Yan and Wang describes an agreement algorithm that involves nodes that are entering and exiting communication channels \cite{Yan2007}. An algorithm could be adapted to the scenario that involves a sensor node losing contact with the rest of its redundancy group. In the algorithm described in \cite{Yan2007} one could implement a method for reestablishing contact with a sensor node even while in the middle of voting. During normal operation under this algorithm a single voting rounds consists of:
\begin{enumerate}
	\item nodes collecting data;
	\item pass collected data to other nodes; and
	\item vote based on received data \cite{Yan2007}.
\end{enumerate} 
All nodes in the group then exchange their values and then vote internally on the values. The nodes then pass exchange the results of there voting and vote once more. After the second voting ``session'' all nodes should be agreeing on the same value. According to the algorithm, if a node loses contact it is no longer included in voting for that round unless it reconnects before the end of the second voting ``session''. If a node reconnects before the second voting algorithm all other nodes pass the results of the second exchange to the new node(s). Once data is transmitted the second ``session'' of voting occurs and at this point all nodes should have the same value \cite{Yan2007}. This algorithm should work for nodes that temporarily lose contact to the group without the group losing accuracy.

This form of dynamic agreement is very practical in real-world scenarios. For example, research is being conducted that involves a short range communication system between automobiles and transport infrastructure. This communication should, in theory, decrease the number of traffic collisions by reporting upcoming traffic conditions to a driver. If a car down the road stops suddenly it can send out a broadcast that traffic has stopped and cars up the road can be warned before a pile-up is inevitable. Communication and node agreement in this type of scenario must have contingencies for nodes leaving and entering such a network. The algorithm described in this section is best fit for these conditions.  In fact, some of the issues explored in \cite{Waltrip2015} such as packet loss due to collisions or vehicles missing beacon messages in the control channel in Dedicated Short-Range Communication (DSRC) applications could benefit from ad hoc agreement.

\section{Conclusions}\label{sec:conclusions}
The carte blanche implementation of traditional fault models is inappropriate in the autonomous vehicle domain.  We found that agreement algorithms that take into consideration the fragility of communication links in wireless sensor networks as well as fault models that detect and tolerate faults in data fusion algorithms are necessary \cite{Biely2007,Bader2014}.  Agreement can also be accomplished in the presence of node failures by removing or replacing known fault nodes \cite{Ren2001}.  In addition to agreement in regards to data fusion, we can extrapolate this to cover decision fusion in a similar fashion as well \cite{Clouqueur2004}.  

A novel approach for exploring new dynamic fault models is to play repeated, evolutionary games in a game-theoretic framework where Byzantine generals act as players with the goal of arriving at equilibrium where the payoff is reliability \cite{Ma2008}.  We also posit that dynamic agreement algorithms have practical applications in emerging technologies such as inter-vehicle and infrastructure communication.

\bibliographystyle{IEEEtran}
\bibliography{./CS548-Bibliography}

\end{document}